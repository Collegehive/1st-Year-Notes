# 1.f Properties of Matrix Multiplication


Matrix multiplication has several important properties that differ from regular arithmetic multiplication. Understanding these properties is crucial for working with matrices in various mathematical contexts.

## 1. **Associativity**:
Matrix multiplication is associative, meaning the order in which matrices are multiplied does not affect the final result (as long as the dimensions are compatible).

\[
(A \cdot B) \cdot C = A \cdot (B \cdot C)
\]

### Example:
Let \( A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix} \), \( B = \begin{bmatrix} 2 & 0 \\ 1 & 3 \end{bmatrix} \), and \( C = \begin{bmatrix} 4 & 1 \\ 2 & 3 \end{bmatrix} \).

\[
(A \cdot B) \cdot C = \begin{bmatrix} 4 & 7 \\ 10 & 15 \end{bmatrix} \cdot \begin{bmatrix} 4 & 1 \\ 2 & 3 \end{bmatrix} = \begin{bmatrix} 24 & 17 \\ 52 & 39 \end{bmatrix}
\]

\[
A \cdot (B \cdot C) = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix} \cdot \begin{bmatrix} 10 & 9 \\ 10 & 9 \end{bmatrix} = \begin{bmatrix} 30 & 27 \\ 70 & 63 \end{bmatrix}
\]

Both results are equal, showing that matrix multiplication is associative.

---

## 2. **Distributivity**:
Matrix multiplication is distributive over matrix addition. This property holds for both left and right multiplication.

\[
A \cdot (B + C) = A \cdot B + A \cdot C
\]
\[
(B + C) \cdot A = B \cdot A + C \cdot A
\]

### Example:
Let \( A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix} \), \( B = \begin{bmatrix} 5 & 6 \\ 7 & 8 \end{bmatrix} \), and \( C = \begin{bmatrix} 9 & 10 \\ 11 & 12 \end{bmatrix} \).

First, calculate \( B + C \):

\[
B + C = \begin{bmatrix} 5+9 & 6+10 \\ 7+11 & 8+12 \end{bmatrix} = \begin{bmatrix} 14 & 16 \\ 18 & 20 \end{bmatrix}
\]

Now, calculate \( A \cdot (B + C) \):

\[
A \cdot \begin{bmatrix} 14 & 16 \\ 18 & 20 \end{bmatrix} = \begin{bmatrix} 1 \cdot 14 + 2 \cdot 18 & 1 \cdot 16 + 2 \cdot 20 \\ 3 \cdot 14 + 4 \cdot 18 & 3 \cdot 16 + 4 \cdot 20 \end{bmatrix} = \begin{bmatrix} 50 & 56 \\ 114 & 128 \end{bmatrix}
\]

Now, calculate \( A \cdot B + A \cdot C \):

\[
A \cdot B = \begin{bmatrix} 1 \cdot 5 + 2 \cdot 7 & 1 \cdot 6 + 2 \cdot 8 \\ 3 \cdot 5 + 4 \cdot 7 & 3 \cdot 6 + 4 \cdot 8 \end{bmatrix} = \begin{bmatrix} 19 & 22 \\ 43 & 50 \end{bmatrix}
\]
\[
A \cdot C = \begin{bmatrix} 1 \cdot 9 + 2 \cdot 11 & 1 \cdot 10 + 2 \cdot 12 \\ 3 \cdot 9 + 4 \cdot 11 & 3 \cdot 10 + 4 \cdot 12 \end{bmatrix} = \begin{bmatrix} 31 & 34 \\ 71 & 78 \end{bmatrix}
\]
\[
A \cdot B + A \cdot C = \begin{bmatrix} 19 & 22 \\ 43 & 50 \end{bmatrix} + \begin{bmatrix} 31 & 34 \\ 71 & 78 \end{bmatrix} = \begin{bmatrix} 50 & 56 \\ 114 & 128 \end{bmatrix}
\]

Thus, \( A \cdot (B + C) = A \cdot B + A \cdot C \), confirming the distributive property.

---

## 3. **Non-Commutativity**:
Matrix multiplication is **not commutative**, meaning in general, \( A \cdot B \neq B \cdot A \).

### Example:
Let \( A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix} \) and \( B = \begin{bmatrix} 5 & 6 \\ 7 & 8 \end{bmatrix} \).

\[
A \cdot B = \begin{bmatrix} 1 \cdot 5 + 2 \cdot 7 & 1 \cdot 6 + 2 \cdot 8 \\ 3 \cdot 5 + 4 \cdot 7 & 3 \cdot 6 + 4 \cdot 8 \end{bmatrix} = \begin{bmatrix} 19 & 22 \\ 43 & 50 \end{bmatrix}
\]

\[
B \cdot A = \begin{bmatrix} 5 \cdot 1 + 6 \cdot 3 & 5 \cdot 2 + 6 \cdot 4 \\ 7 \cdot 1 + 8 \cdot 3 & 7 \cdot 2 + 8 \cdot 4 \end{bmatrix} = \begin{bmatrix} 23 & 34 \\ 31 & 46 \end{bmatrix}
\]

Since \( A \cdot B \neq B \cdot A \), matrix multiplication is not commutative.

---

# Determinants

## Definition
The **determinant** is a scalar value that can be computed from a square matrix. Determinants are useful in solving linear systems, finding the inverse of a matrix, and determining properties like whether a matrix is invertible.

### Formula for 2x2 Matrix:
For a matrix \( A = \begin{bmatrix} a & b \\ c & d \end{bmatrix} \), the determinant of \( A \), denoted as det(A), is given by:

\[
\text{det}(A) = ad - bc
\]

---

# Properties of Determinants (Statement Only)

1. **Determinant of the product of two matrices**: If \( A \) and \( B \) are square matrices, then \( \text{det}(A \cdot B) = \text{det}(A) \cdot \text{det}(B) \).
   
2. **Determinant of a transpose**: The determinant of a matrix is equal to the determinant of its transpose, i.e., \( \text{det}(A^T) = \text{det}(A) \).

3. **Determinant of the inverse**: If a matrix \( A \) is invertible, then \( \text{det}(A^{-1}) = \frac{1}{\text{det}(A)} \).

4. **Row operations**: 
   - Swapping two rows of a matrix multiplies the determinant by -1.
   - Multiplying a row by a scalar multiplies the determinant by that scalar.
   - Adding a multiple of one row to another does not change the determinant.

---

## Example 1:
Let \( A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix} \).

The determinant of \( A \) is:

\[
\text{det}(A) = 1 \cdot 4 - 2 \cdot 3 = 4 - 6 = -2
\]

---

## Example 2:
Let \( B = \begin{bmatrix} 2 & 5 \\ 1 & 3 \end{bmatrix} \).

The determinant of \( B \) is:

\[
\text{det}(B) = 2 \cdot 3 - 5 \cdot 1 = 6 - 5 = 1
\]

---

## Conclusion
- **Matrix multiplication** has key properties such as associativity, distributivity, and non-commutativity.
- The **determinant** provides crucial information about the matrix, such as whether it is invertible.
- The **properties of determinants** simplify calculations and are essential in linear algebra applications.
